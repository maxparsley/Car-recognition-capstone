{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports (reminder to come back and clean this up)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os\n",
    "from PIL import Image\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data = scipy.io.loadmat('G:\\\\\\\\capstone files\\\\\\\\data\\\\\\\\archive (1)\\\\\\\\cars_annos.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the only two I care about is \"annotations\" and \"class_names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = pd.DataFrame(data['class_names'])\n",
    "class_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataframes for each column to make it easier to work with\n",
    "relative_im_path = pd.DataFrame(data['annotations']['relative_im_path']).transpose()\n",
    "bbox_x1 = pd.DataFrame(data['annotations']['bbox_x1']).transpose()\n",
    "bbox_x2 = pd.DataFrame(data['annotations']['bbox_x2']).transpose()\n",
    "bbox_y1 = pd.DataFrame(data['annotations']['bbox_y1']).transpose()\n",
    "bbox_y2 = pd.DataFrame(data['annotations']['bbox_y2']).transpose()\n",
    "class_id = pd.DataFrame(data['annotations']['class']).transpose()\n",
    "test = pd.DataFrame(data['annotations']['test']).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the dataframes into one\n",
    "annotations = pd.concat([relative_im_path, bbox_x1, bbox_y1, bbox_x2, bbox_y2, class_id, test], axis=1)\n",
    "annotations.columns = ['relative_im_path', 'x1', 'y1', 'x2', 'y2', 'class_id', 'test']\n",
    "annotations.head()\n",
    "#values are in the same order, confirmed through the matlab file using octave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cast all columns to int except for relative_im_path\n",
    "annotations[annotations.columns.difference(['relative_im_path'])] = annotations[annotations.columns.difference(['relative_im_path'])].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "#set the paths for the images\n",
    "train_image_paths = glob.glob('G:/capstone files/data/archive (1)/cars_train/cars_train/*.jpg')\n",
    "test_image_paths = glob.glob('G:/capstone files/data/archive (1)/cars_test/cars_test/*.jpg')\n",
    "\n",
    "#resize all the images to 224x224 and store in local memory to save ram\n",
    "def save_resized_images(image_paths, output_dir, size=(224, 224)):\n",
    "    for image_paths in image_paths:\n",
    "        with Image.open(image_paths) as img:\n",
    "            resized_img = img.resize(size)\n",
    "            output_path = os.path.join(output_dir, os.path.basename(image_paths))\n",
    "            resized_img.save(output_path)\n",
    "#set the output directories for the resized images\n",
    "train_output_dir = \"G:/capstone files/data/cars train resized\"\n",
    "test_output_dir = \"G:/capstone files/data/cars test resized\"\n",
    "#make the directories if they don't exist\n",
    "if not os.path.exists(train_output_dir):\n",
    "    os.makedirs(train_output_dir)\n",
    "if not os.path.exists(test_output_dir):\n",
    "    os.makedirs(test_output_dir)\n",
    "\n",
    "save_resized_images(train_image_paths, train_output_dir)\n",
    "save_resized_images(test_image_paths, test_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get new paths for the resized images\n",
    "resized_train_image_path = glob.glob(train_output_dir + '/*.jpg')\n",
    "resized_test_image_path = glob.glob(test_output_dir + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#preprocess the images and store them in a dataset using tensorflow data api\n",
    "def preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "train_images = tf.data.Dataset.from_tensor_slices(resized_train_image_path)\n",
    "train_images = train_images.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_images = tf.data.Dataset.from_tensor_slices(resized_test_image_path)\n",
    "test_images = test_images.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first image in the training set\n",
    "first_image = list(train_images.take(1))[0]\n",
    "#check to see if it is the right size\n",
    "first_image_shape = first_image.shape\n",
    "print(first_image_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_annotations = annotations.drop(annotations[annotations['test'] == 1].index)\n",
    "test_annotations = annotations.drop(annotations[annotations['test'] == 0].index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
